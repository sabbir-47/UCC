\section{Related Work}


%The increasing enthusiasm and consciousness of reducing energy consumption leads to smarter ways to consume energy in cloud data centers. While an efficient energy management technique in data center can reduce unnecessary use of brown energy and better utilize green energy without going to waste, smarter ways of consuming energy by an application can further reduce carbon footprint.


\paragraph*{\textbf{Green Energy aware Application adaptation}}

%rutgers work 2ta, yunbo work, geo distributed cloud.
%batch job
Goiri et al. \cite{GreenSlot} proposed \emph{GreenSlot}, a parallel batch job scheduler for a datacenter powered by an on-site renewable plant. Based on the historical data and weather forecast, GreenSlot predicts the amount of solar energy that will likely be available in the future and subject to its predictions, it schedules the workload by the order of least slack time first (LSTF), to maximize the green energy consumption while meeting the job's deadlines by creating resource reservations into the future. Later, their work evolved into data processing framework by proposing \emph{GreenHadoop} \cite{GreenHadoop}. The idea relies on deferring background
computations \emph{e.g.,} data and log analysis, long simulations etc. that can be delayed by a bounded amount of time in a data center to take advantage of green energy availability while minimizing brown electricity cost. The idea is to run fewer servers when brown energy is cheap, and even fewer (if at all necessary) when brown energy is expensive. In conclusion, their proposal leads to operating few
hadoop clusters when green energy is scarce. 
Similar to this work, authors \cite{GreenPar} proposed \emph{GreenPar}, a scheduler for parallel high-performance applications to maximize using green energy in a partially powered data center and reduce brown energy consumption, while respecting performance aware SLA.  When green energy is available, GreenPar increases the resource allocations to active jobs to reduce runtimes by speeding up the processes while slow down the jobs to a maximum runtime slowdown percentage that is defined in SLA during the scarcity of the green energy. However, all these works focused specifically around batch like applications where job arrives with a deadline, hence can be deferred and scheduled by following the green energy availability. On the other hand, we propose to create green energy awareness around the interactive kind of application to to be self adapted with the presence/absence of green energy. Recently, Klein et al. \cite{brownout} introduced Brownout paradigm for dynamic adaptation in interactive application through control theory to withstand in
unpredictable runtime variations. Content reconfiguration takes into account only the system response time so that to prevent system instability in sudden workload burstiness. While the novelty of the approach is well understood,
how the controller should be designed to take the advantage of the presence of green energy and 
implemented in
massively virtualized and distributed cloud environment to exploit the elastic nature of infrastructure,
has not been addressed.

%geo-distributed cloud!
To this, in \cite{GreenWare}, the authors proposed \emph{GreenWare}, a middleware system that maximize the usage of green energy in geo-distributed cloud scale data centers by dynamically dispatching workload requests by following renewable, subject to energy budget constraint. The middleware performs three steps: computes the hourly energy budget and historical behavior of workload, runs an optimization algorithm based on constrained optimization technique, lastly dispatches requests according to optimization plan. Similar to this, \cite{not-easy} proposed a flow optimization based framework for request-routing considering the trade-off between access latency, carbon footprint and electricity costs to upgrade the plan of choosing data center in specific intervals. Again these works focused more on load-balancing of user requests to different data centers to maximize the usage of green energy rather relying on application adaptation on the fly.



\paragraph*{\textbf{Platform adaptation}}

%put corentin dupont's work here. Some other functional-Non functional adaptation.
Shi et al. \cite{shi} proposed two control layer, one responsible for allocating resources to VM's depending on the performance, the other one as a power saving layer to dynamically save energy by tuning voltage and frequency (DVFS) while resource requirement is low. Both layers are designed as autonomic loops in a coordinated
manner to control cluster level resources. Later, Hankendi et al. \cite{adaptcap} proposed an adaptive framework that jointly utilizes system (DVFS) and application-level
adaptation to improve efficiency of multi-core servers and reduction of power consumption. Application-level adaptation has been utilized to meet the performance
and accuracy constraints, whereas to meet power constraints, system-level
management was adopted. On the other hand, we propose to adopt sequential execution  of adaptation technique both at application and infrastructure level that not only met performance but also reduced energy consumption at significant portion. 

In contrast to prevoius works, authors at \cite{corentin} presented an Energy Adaptive Software Controller (\emph{EASC}) to make task and service oriented application adaptive to renewable energy availability. The work was part of by DC4Cities project \footnote{An European project on environmentally sustainable data centers for samart cities. Ended on 2016. \url{http://www.dc4cities.eu}}, which aimed at gathering renewable energy related information from energy providers and energy constraint directives from Energy monitoring authority (in context of Smart city) through an interface. Following the information, the PaaS layer is responsible to adapt the application by satisfying energy related constraints to consume more green energy, therefore building more eco-efficient policies for data center. The authors proposed to forward the energy related information to PaaS level via an API, so that an optimization plan can be invoked which involves desired working modes of an application considering energy and SLA constraints. However, service oriented application \emph{i.e.,} interactive application is defined as running web, database and mail servers and higher mode depicts multiple data center site is active with full capacity while lowest mode indicates running a single site with minimum capacity. Apart from that, Moreno et al. \cite{garlan1} proposed how different non-conflicting tactics (\emph{e.g.,} remove one software component and add one server) can be triggered simultaneously so that system can transition from current to desired state. The challenge is to estimate how two types of tactics when applied together reacts to the system. For instance, removing software component can have immediate transition, whereas adding one server can make a delayed transition which is also associated with cost. Depending on the goal, the utility function can be maximized by choosing proper adaptation tactics. Again these works ignored how to adapt and define tactics to leverage green energy availability to either consume more green energy or lesser brown energy.

